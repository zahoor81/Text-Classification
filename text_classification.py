# -*- coding: utf-8 -*-
"""Text classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19sihqZgR9FhatDna7rzS6dzPBEkw1TFE

Movie Review Dataset. This is a dataset of containing 5,331 positive and 5,331 negative processed sentences from Rotten Tomatoes movie reviews.

**default**

text: a string feature.

label: a classification label, with possible values including neg (0), pos (1).

**Data Distribution**

name = default

train	= 8530

validation	= 1066

test = 1066
"""

!pip install -U datasets fsspec

from datasets import load_dataset

ds = load_dataset("rotten_tomatoes")

ds

ds["train"][0, -1]

"""These short reviews are either labeled as positive (1) or negative (0). This
 means that we will focus on binary sentiment classification.
"""

import pandas as pd
import numpy as np

ds.column_names

df = pd.DataFrame(ds['train'][:])
print(df.head())

"""##Using Task-specifc models"""

from transformers import pipeline
 # Path to our HF model
 model_path = "cardiffnlp/twitter-roberta-base-sentiment-latest"

# Load model into pipeline
pipe = pipeline(
model=model_path,
tokenizer=model_path,
return_all_scores=True,
device="cuda:0")

import numpy as np
from tqdm import tqdm
from transformers.pipelines.pt_utils import KeyDataset

# Run inference
y_pred = []

for output in tqdm(pipe(KeyDataset(ds["test"], "text")), total=len(ds["test"])):
    negative_score = output[0]["score"]
    positive_score = output[2]["score"]

    # Assign class based on the higher score
    assignment = np.argmax([negative_score, positive_score])
    y_pred.append(assignment)

from sklearn.metrics import classification_report

def evaluate_performance(y_true, y_pred):
    """Create and print the classification report"""
    performance = classification_report(
        y_true,
        y_pred,
        target_names=["Negative Review", "Positive Review"]
    )
    print(performance)

evaluate_performance(ds["test"]["label"], y_pred)



"""Using another model specifically trained for reviews sentiment"""

from transformers import pipeline
from datasets import load_dataset
from transformers.pipelines.pt_utils import KeyDataset
import numpy as np
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix

ds = load_dataset("rotten_tomatoes")

# Load text classification pipeline with all class scores
pipe = pipeline(
    "text-classification",
    model="distilbert/distilbert-base-uncased-finetuned-sst-2-english",
    top_k=None,
    device=0     # Use GPU if available; use device=-1 for CPU
)

#  inference
y_pred = []
for output in tqdm(pipe(KeyDataset(ds["test"], "text")), total=len(ds["test"])):
    scores = {item["label"]: item["score"] for item in output}

    assignment = np.argmax([scores["NEGATIVE"], scores["POSITIVE"]])
    y_pred.append(assignment)

# Ground truth labels
y_true = ds["test"]["label"]


def evaluate_performance(y_true, y_pred):
    """Create and print the classification report and confusion matrix"""
    print("Classification Report:")
    print(classification_report(y_true, y_pred, target_names=["Negative Review", "Positive Review"]))

    print("\nConfusion Matrix:")
    print(confusion_matrix(y_true, y_pred))


evaluate_performance(y_true, y_pred)



"""##using Embedding Models"""

from sentence_transformers import SentenceTransformer
model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")

#converting text into emebdings
train_embeddings = model.encode(ds["train"]["text"],
show_progress_bar=True)
test_embeddings = model.encode(ds["test"]["text"],
show_progress_bar=True)

#this will show that each embedding(8530) cotains 768 values
train_embeddings.shape

"""Now that we got embeddings features we will train a classifier now"""

from sklearn.linear_model import LogisticRegression
# Train a logistic regression on our train embeddings
clf = LogisticRegression(random_state=42)
#random state control the randomness
clf.fit(train_embeddings, ds["train"]["label"])

# Predict previously unseen instances
y_pred = clf.predict(test_embeddings)
evaluate_performance(ds["test"]["label"], y_pred)



"""Zero Shot Classification"""

# Create embeddings for our labels
label_embeddings = model.encode(["A negative movie review",  "A positive movie review"])

from sklearn.metrics.pairwise import cosine_similarity
 # Find the best matching label for each document
 sim_matrix = cosine_similarity(test_embeddings, label_embeddings)
 y_pred = np.argmax(sim_matrix, axis=1)

evaluate_performance(ds["test"]["label"], y_pred)



"""Using T5 model - Text-to-Text Transfer Transformer"""

# Load our model
pipe = pipeline("text2text-generation",
model="google/flan-t5-small",
device="cuda:0")

# Prepare prompt
 prompt = "Is the following sentence positive or negative? "
 data = ds.map(lambda example: {"t5": prompt + example['text']})
 data

#  inference
y_pred = []

for output in tqdm(pipe(KeyDataset(data["test"], "t5")), total=len(data["test"])):
    text = output[0]["generated_text"].strip().lower()
    y_pred.append(0 if text == "negative" else 1)

evaluate_performance(data["test"]["label"], y_pred)

